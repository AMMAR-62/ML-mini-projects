{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello .... Ammar .. Hi!!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hello_world(name):\n",
    "    return f\"hello .... {name} .. Hi!!\"\n",
    "hello_world(\"Ammar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn = hello_world, inputs=\"text\", outputs = \"text\")\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customised Components in Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn = hello_world, inputs = gr.inputs.Textbox(lines=5, placeholder=\"Enter your input here ... \"), outputs = \"text\")\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sepia filter example (image input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([[.393, .769, .189], [.349, .686, .168], [.272, .534, .131]])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "interface = gr.Interface(fn = sepia, inputs = gr.inputs.Image(shape=(200, 200)), outputs = \"image\")\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular data as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sales_projections(employee_data):\n",
    "    sales_data = employee_data.iloc[:, 1:4].astype(\"int\").to_numpy()\n",
    "    regression_values = np.apply_along_axis(lambda row: \n",
    "        np.array(np.poly1d(np.polyfit([0,1,2], row, 2))), 0, sales_data)\n",
    "    projected_months = np.repeat(np.expand_dims(\n",
    "        np.arange(3,12), 0), len(sales_data), axis=0)\n",
    "    projected_values = np.array([\n",
    "        month * month * regression[0] + month * regression[1] + regression[2]\n",
    "        for month, regression in zip(projected_months, regression_values)])\n",
    "    plt.plot(projected_values.T)\n",
    "    plt.legend(employee_data[\"Name\"])\n",
    "    return employee_data, plt.gcf(), regression_values\n",
    "\n",
    "iface = gr.Interface(sales_projections, \n",
    "    gr.inputs.Dataframe(\n",
    "        headers=[\"Name\", \"Jan Sales\", \"Feb Sales\", \"Mar Sales\"],\n",
    "        default=[[\"Jon\", 12, 14, 18], [\"Alice\", 14, 17, 2], [\"Sana\", 8, 9.5, 12]]\n",
    "    ),\n",
    "    [\n",
    "        \"dataframe\",\n",
    "        \"plot\",\n",
    "        \"numpy\"\n",
    "    ],\n",
    "    description=\"Enter sales figures for employees to predict sales trajectory over year.\"\n",
    ")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **How to use multiple inputs in gradio applications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMI(name, height, weight, feeling):\n",
    "    bmiVal = weight / (height**2)\n",
    "    result_emoticon = \"ðŸ˜Š\" if bmiVal < 10 else \"ðŸ˜¢\"\n",
    "    output_str = f\"Hello ðŸ˜‰ {name} ... \\nyour BMI is.... {bmiVal}\"\n",
    "    txt = \"Happy\" if feeling else \"Sad\"\n",
    "    return (output_str, result_emoticon, txt)\n",
    "\n",
    "# BMI(\"ammar\", 1.2, 80, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(\n",
    "    fn = BMI,\n",
    "    inputs = ['text', gr.inputs.Slider(0, 200, label= 'Height in Meters'), gr.inputs.Slider(0, 100, label=\"Weight in Kg\"), gr.inputs.Checkbox(label=\"feeling happy\")],\n",
    "    outputs = ['text', 'text', 'text'],\n",
    "    examples = [['ammar', 175,50, True], \n",
    "                ['Someone', 180, 65, True], \n",
    "                ['No-one', 190, 99, False]],\n",
    "    description=\"Flag if you find any erroneous output\",\n",
    "    # theme=\"darkhuggingface\",\n",
    "    css = \"\"\"\n",
    "    body {\n",
    "        background-color: grey;\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "interface.launch(auth={'ammar', 'Something@123'}, auth_message = \"Check your <strong>login details</strong> sent to your <i>email</i>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256M/256M [00:17<00:00, 15.6MB/s] \n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<?, ?B/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 226k/226k [00:02<00:00, 109kB/s]  \n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "sentiment = pipeline(\"sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9997990727424622}]\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment(input_text):\n",
    "    return sentiment(input_text)\n",
    "\n",
    "result = get_sentiment(\"The movie was very bad\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1ead7b8d490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x1eaa50272b0>,\n",
       " 'http://127.0.0.1:7860/',\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface = gr.Interface(fn = get_sentiment, inputs = \"text\", outputs = [\"text\"], title=\"Sentiment Analysis\", description=\"Get Sentiment Negative / Positive for the given input\" )\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8367bf0744f19d6bd003cb076841882ea5aedef6c3ddfca5e4e40e9bf2a2a9c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
